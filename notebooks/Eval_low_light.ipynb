{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code intended to evaluate the performances of Orbslam3 and DSO using custom dataset in TUM format.\n",
    "Requirements.\n",
    "1) Container containing DSO (custom)\n",
    "2) Container containing ORBSLAM3 (custom)\n",
    "3) Folder containing the datasets\n",
    "4) Evo tools ;D\n",
    "'''\n",
    "import docker\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "outputs": [],
   "source": [
    "def copy_to_container(container, container_dest_path, dataset_dir):\n",
    "    print(\"Copying '{}' in \\\"{}\\\" \".format(dataset_dir,container_dest_path))\n",
    "    temp_dir_processing = os.path.join(os.getcwd(), \"temp\",\"\".join([\"curr_dataset\",\".tar.gz\"]))\n",
    "\n",
    "    print(\"\\t - 1) Compressing {}\".format(temp_dir_processing))\n",
    "    with tarfile.open(temp_dir_processing, \"w:gz\") as tar:\n",
    "        tar.add(dataset_dir, arcname=os.path.basename(dataset_dir))\n",
    "    print(\"\\t\\tDone!\")\n",
    "\n",
    "    print(\"\\t - 2) Copying into DSO containter: {}\".format(container.name))\n",
    "    with open(temp_dir_processing, 'rb') as fd:\n",
    "        ok = dso_container.put_archive(path=container_dest_path, data=fd)\n",
    "        if not ok:\n",
    "            raise Exception('Put file failed')\n",
    "        else:\n",
    "            print(\"\\t\\tDone!\")\n",
    "    if os.path.exists(temp_dir_processing):\n",
    "        print(\"\\t - 3) Removing the temp file:{}\".format(temp_dir_processing))\n",
    "        os.remove(temp_dir_processing)\n",
    "        print(\"\\t\\tDone!\")\n",
    "    else:\n",
    "        print('Unable to remove {} \\n this not a critucal problem, proceed...'.format(temp_dir_processing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config path: /home/croc/Documenti/Repositories/evoTools/notebooks/config\n",
      "\t-Docker config loaded;\n",
      "\t-Local config loaded;\n",
      "DSO CONTAINTER CONFIGURATIONS\n",
      "\t{'Id': '7a0bedaae163', 'Names': 'test_dso', 'datasetFolder': '/root/Archive/Dataset/', 'Algorithm': {'binPath': '/root/Programs/dso/build/bin/', 'exec': 'dso_dataset_params', 'output_file': 'result.txt', 'configs': {'files': 'images.zip', 'calib': 'camera.txt', 'gamma': 'pcalib.txt', 'vignette': 'vignette.png'}, 'params': {'ImmatureDensity': 400, 'PointDensity': 800, 'minFrames': 5, 'maxFrames': 7, 'maxOptIterations': 6, 'minOptIterations': 1, 'speed': 0, 'mode': 0, 'nogui': 1, 'quiet': 1}}}\n",
      "ORBSLAM CONTAINTER CONFIGURATIONS\n",
      "\t{'Id': '4ecad379b081', 'Names': 'test_orbslam3', 'datasetFolder': '/root/Archive/Dataset/', 'Algorithm': {'binPath': '/root/Programs/ORB_SLAM3/Examples/Monocular/'}}\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# LOAD CONFIG\n",
    "######################################################################\n",
    "root_path = os.getcwd()\n",
    "config_path = os.path.join(root_path, \"config\")\n",
    "docker_config = os.path.join(config_path, \"docker_containers.yaml\")\n",
    "local_config = os.path.join(config_path, \"local_host_params.yaml\")\n",
    "print(\"Current config path: {}\".format(config_path))\n",
    "try:\n",
    "    with open(docker_config, \"r\") as yamlfile:\n",
    "        docker_data_cfg = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "        print(\"\\t-Docker config loaded;\")\n",
    "except OSError:\n",
    "    print(\"Could not open/read file:\", docker_config)\n",
    "    sys.exit()\n",
    "\n",
    "try:\n",
    "    with open(local_config, \"r\") as yamlfile:\n",
    "        local_data_cfg = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "        print(\"\\t-Local config loaded;\")\n",
    "except OSError:\n",
    "    print(\"Could not open/read file:\", local_config)\n",
    "    sys.exit()\n",
    "\n",
    "# Get the configurations for the containers\n",
    "dso_container_config = docker_data_cfg[\"Containers\"][0][\"DSO\"]\n",
    "orb_container_config = docker_data_cfg[\"Containers\"][1][\"ORBSLAM3\"]\n",
    "\n",
    "print(\"DSO CONTAINTER CONFIGURATIONS\")\n",
    "print(\"\\t{}\".format(dso_container_config))\n",
    "\n",
    "print(\"ORBSLAM CONTAINTER CONFIGURATIONS\")\n",
    "print(\"\\t{}\".format(orb_container_config))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# DOCKER SET-UP\n",
    "######################################################################\n",
    "\n",
    "# Get the client\n",
    "client_dk = docker.from_env()\n",
    "\n",
    "# Retrieve the containers\n",
    "orb_container = [cont for cont in client_dk.containers.list(all=True) if cont.short_id == orb_container_config[\"Id\"]][0]\n",
    "dso_container = [cont for cont in client_dk.containers.list(all=True) if cont.short_id == dso_container_config[\"Id\"]][0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container test_orbslam3 Already started\n",
      "Container test_dso Already started\n"
     ]
    }
   ],
   "source": [
    "# Start the two containers\n",
    "if orb_container.status == 'exited':\n",
    "    orb_container.start()\n",
    "    print(\"Container {} Started\".format(orb_container.name))\n",
    "elif orb_container.status ==\"running\":\n",
    "     print(\"Container {} Already started\".format(orb_container.name))\n",
    "\n",
    "if dso_container.status == 'exited':\n",
    "    dso_container.start()\n",
    "    print(\"Container {} Started\".format(dso_container.name))\n",
    "elif dso_container.status ==\"running\":\n",
    "    print(\"Container {} Already started\".format(dso_container.name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# DATASET LOADING\n",
    "######################################################################\n",
    "\n",
    "#Common Parameters\n",
    "datasets_root_path = local_data_cfg[\"Datasets\"][\"root_path\"]\n",
    "datasets_map_folder = local_data_cfg[\"Datasets\"][\"map_folder\"]\n",
    "datasets_data_folder = local_data_cfg[\"Datasets\"][\"data_folder\"]\n",
    "datasets_eva_folder = local_data_cfg[\"Datasets\"][\"out_eva_folder\"]\n",
    "\n",
    "#Datasets selected\n",
    "dataset_list = local_data_cfg[\"Datasets\"][\"Scenarios\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering subsets of Corridor_A: ['Corridor_A_D_190', 'Corridor_A_D_60', 'Corridor_A_D_255', 'Corridor_A_D_85', 'Corridor_A_D_127', 'Corridor_A_L', 'Corridor_A_D_25']\n"
     ]
    }
   ],
   "source": [
    "# Sub-Datasets Discovering\n",
    "dataset_selected = list(dataset_list.keys())[0]\n",
    "folder_dataset_sel=dataset_list[dataset_selected][\"folder_name\"]\n",
    "path_dataset = os.path.join(datasets_root_path, folder_dataset_sel)\n",
    "if os.path.isdir(path_dataset):\n",
    "    elem = [elem for elem in os.listdir(os.path.join(path_dataset, datasets_data_folder))]\n",
    "    print(\"Discovering subsets of {}: {}\".format(dataset_selected,elem))\n",
    "else:\n",
    "    elem = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      " Processing with DSO the Corridor_A_L dataset\n",
      "**************************************************\n",
      "Copying '/home/croc/Documenti/Trajectories/excasi/Datasets/TUM Format/Corridor_A_L' in \"/root/Archive/Dataset/\" \n",
      "\t - 1) Compressing /home/croc/Documenti/Repositories/evoTools/notebooks/temp/curr_dataset.tar.gz\n",
      "\t\tDone!\n",
      "\t - 2) Copying into DSO containter: test_dso\n",
      "\t\tDone!\n",
      "\t - 3) Removing the temp file:/home/croc/Documenti/Repositories/evoTools/notebooks/temp/curr_dataset.tar.gz\n",
      "\t\tDone!\n",
      "\n",
      " On container \"test_dso\" execute the following command:  \n",
      "\tbash -c \"cd /root/Programs/dso/build/bin/ && ./dso_dataset_params files=/root/Archive/Dataset/Corridor_A_L/images.zip calib=/root/Archive/Dataset/Corridor_A_L/camera.txt gamma=/root/Archive/Dataset/Corridor_A_L/pcalib.txt vignette=/root/Archive/Dataset/Corridor_A_L/vignette.png ImmatureDensity=400 PointDensity=800 minFrames=5 maxFrames=7 maxOptIterations=6 minOptIterations=1 speed=0 mode=0 nogui=1 quiet=1\" \n",
      "\t Done!\n",
      "\n",
      " Removing /root/Archive/Dataset/Corridor_A_L from test_dso\n",
      "\t Done!\n",
      "\n",
      "Renaming the results, using the command: bash -c \"cd /root/Programs/dso/build/bin/ && mv result.txt Corridor_A_L_DSO.txt\"\n",
      "\tDone!\n"
     ]
    }
   ],
   "source": [
    "# TODO: This must be extended to ORBSLAM and for all the subsets\n",
    "# We'll try to process just the CorridorA\n",
    "curr_dataset = elem[5]\n",
    "algorithm = \"DSO\"\n",
    "print(\"\\n\"+ \"*\"*50 + \"\\n Processing with {} the {} dataset\".format(algorithm, curr_dataset) +\"\\n\"+ \"*\"*50)\n",
    "\n",
    "# Compose the full path of the desired Dataset\n",
    "path_sub_dataset = os.path.join(path_dataset, datasets_data_folder, curr_dataset)\n",
    "\n",
    "# Get the destination directory\n",
    "destination_path = dso_container_config[\"datasetFolder\"]\n",
    "\n",
    "# Transfer the dataset into the container\n",
    "copy_to_container(dso_container, destination_path, path_sub_dataset)\n",
    "container_actual_data = os.path.join(destination_path, curr_dataset)\n",
    "\n",
    "\n",
    "# Preparing the cmd for DSO:\n",
    "dso_container_config_algorithm = dso_container_config[\"Algorithm\"]\n",
    "\n",
    "# 1) Change directory command\n",
    "chg_dir_string=\"\".join([\"cd\", \" \", dso_container_config_algorithm[\"binPath\"]])\n",
    "\n",
    "# 2a) Executable command\n",
    "executable_string = str(os.path.join(\".\",  dso_container_config_algorithm[\"exec\"]))\n",
    "\n",
    "# 2b) Configs command\n",
    "config_string = \"\"\n",
    "first = True\n",
    "for config in dso_container_config_algorithm[\"configs\"]:\n",
    "    config_value=dso_container_config_algorithm[\"configs\"][config]\n",
    "    if first:\n",
    "        config_string+=\"\".join([str(config),\"=\",str(os.path.join(container_actual_data,config_value))])\n",
    "        first = False\n",
    "    else:\n",
    "        config_string+=\"\".join([\" \",str(config),\"=\",str(os.path.join(container_actual_data,config_value))])\n",
    "\n",
    "# 2c) Parameters command\n",
    "param_string = \"\"\n",
    "first = True\n",
    "for param in dso_container_config_algorithm[\"params\"]:\n",
    "    param_value=dso_container_config_algorithm[\"params\"][param]\n",
    "    if first:\n",
    "        param_string+=\"\".join([str(param),\"=\",str(param_value)])\n",
    "        first = False\n",
    "    else:\n",
    "        param_string+=\"\".join([\" \",str(param),\"=\",str(param_value)])\n",
    "\n",
    "# 2d) Command String\n",
    "dso_command_string = \"\".join([executable_string, \" \", config_string, \" \", param_string])\n",
    "\n",
    "\n",
    "# 3)  command string\n",
    "command_string = \"\".join([\"bash -c \\\"\", chg_dir_string, \" && \",  dso_command_string, \"\\\"\"])\n",
    "print(\"\\nOn container \\\"{}\\\" execute the following command:  \\n\\t{} \".format(dso_container.name, command_string))\n",
    "\n",
    "# 5) Execute command\n",
    "command_res=dso_container.exec_run(command_string, stdout=True, stderr=True, stdin=False, tty=False, privileged=False, user='', detach=False, stream=False, socket=False, environment=None, workdir=None, demux=False)\n",
    "if command_res[0]==0:\n",
    "    print(\"\\t Done!\")\n",
    "else:\n",
    "    print(\"\\tIt was not possible, error code: {}\".format(command_res))\n",
    "\n",
    "\n",
    "# 6) Remove the datasets from the container\n",
    "print(\"\\nRemoving {} from {}\".format(container_actual_data,dso_container.name))\n",
    "rm_dataset_cmd = \"\".join([\"bash -c \\\"\",\"rm -r\", \" \", str(container_actual_data),\"\\\"\"])\n",
    "command_res = dso_container.exec_run(rm_dataset_cmd, stdout=True, stderr=True, stdin=False, tty=False, privileged=False, user='', detach=False, stream=False, socket=False, environment=None, workdir=None, demux=False)\n",
    "if command_res[0]==0:\n",
    "    print(\"\\t Done!\")\n",
    "else:\n",
    "    print(\"\\tIt was not possible, error code: {}\".format(command_res))\n",
    "\n",
    "\n",
    "# 7) Rename the result,\n",
    "result_filename = \"\".join([curr_dataset, \"_\", \"DSO.txt\"])\n",
    "cmd_ren= \"\".join([\"bash -c \\\"\", chg_dir_string, \" && \", \"mv\", \" \", dso_container_config_algorithm[\"output_file\"], \" \", result_filename, \"\\\"\"])\n",
    "print(\"\\nRenaming the results, using the command: {}\".format(cmd_ren))\n",
    "command_res = dso_container.exec_run(cmd_ren, stdout=True, stderr=True, stdin=False, tty=False, privileged=False, user='', detach=False, stream=False, socket=False, environment=None, workdir=None, demux=False)\n",
    "if command_res[0]==0:\n",
    "    print(\"\\tDone!\")\n",
    "else:\n",
    "    print(\"\\tIt was not possible, error code: {}\".format(command_res))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
